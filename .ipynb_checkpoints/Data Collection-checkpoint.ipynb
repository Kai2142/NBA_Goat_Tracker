{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import Libraries\n",
   "id": "8ebc9b4639950ad9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:33.743209Z",
     "start_time": "2024-11-23T11:13:33.740952Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T12:02:01.996784Z",
     "start_time": "2024-11-23T12:02:01.992359Z"
    }
   },
   "cell_type": "code",
   "source": "headers = {\"User Agent\": \"Mozilla/5.0\"}",
   "id": "8e85898401aa1d60",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:33.754654Z",
     "start_time": "2024-11-23T11:13:33.750955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read player_extensions csv\n",
    "url_extensions_df = pd.read_csv(\"data/player_extensions.csv\")\n",
    "# Convert Extension Column to list\n",
    "url_extensions = url_extensions_df[\"Player Extension\"].tolist()"
   ],
   "id": "e89b15db8fd4ec3",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:33.757710Z",
     "start_time": "2024-11-23T11:13:33.755873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create List with player links\n",
    "player_links = []\n",
    "def concat_urls(url_extension):\n",
    "    for ext in url_extension:\n",
    "        base_url = \"https://www.basketball-reference.com/\"\n",
    "        player_url = ext\n",
    "        full_url = base_url + player_url\n",
    "        player_links.append(full_url)\n",
    "concat_urls(url_extensions)"
   ],
   "id": "a267e473a8dcc670",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:33.760099Z",
     "start_time": "2024-11-23T11:13:33.758257Z"
    }
   },
   "cell_type": "code",
   "source": "print(player_links[0])",
   "id": "b58dec5355667e25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.basketball-reference.com//players/a/abdulka01.html\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape PPG",
   "id": "c90fa24507259865"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:33.763245Z",
     "start_time": "2024-11-23T11:13:33.761143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_ppg(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)  \n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()  # Raise an exception for bad HTTP status codes\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        p1_div = soup.find(\"div\", {\"class\": \"p1\"})\n",
    "        if p1_div:\n",
    "            ppg_value_element = p1_div.find_all(\"p\")[3] \n",
    "            ppg_value = ppg_value_element.get_text()\n",
    "            return ppg_value.strip()\n",
    "        else:\n",
    "            return \"PPG information not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# print(scrape_ppg(player_links[0]))"
   ],
   "id": "6cf650733f5e963f",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape Rebounds",
   "id": "98dda9673db62c8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:41.324214Z",
     "start_time": "2024-11-23T11:13:33.767705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_trb(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)  \n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()  \n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        p1_div = soup.find(\"div\", {\"class\": \"p1\"})\n",
    "        if p1_div:\n",
    "            ppg_value_element = p1_div.find_all(\"p\")[5] \n",
    "            ppg_value = ppg_value_element.get_text()\n",
    "            return ppg_value.strip()\n",
    "        else:\n",
    "            return \"PPG information not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "print(scrape_trb(player_links[0]))"
   ],
   "id": "67ae731be983c607",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape Assists",
   "id": "bc8ad89863e78486"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:13:48.554883Z",
     "start_time": "2024-11-23T11:13:41.325076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_ast(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)  \n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()  \n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        p1_div = soup.find(\"div\", {\"class\": \"p1\"})\n",
    "        if p1_div:\n",
    "            ppg_value_element = p1_div.find_all(\"p\")[7] \n",
    "            ppg_value = ppg_value_element.get_text()\n",
    "            return ppg_value.strip()\n",
    "        else:\n",
    "            return \"PPG information not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "print(scrape_ast(player_links[0]))"
   ],
   "id": "2fa8db9e596a8da5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape MVP\n",
   "id": "34e1f5b8ab36feb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:38:15.017844Z",
     "start_time": "2024-11-23T11:38:07.746220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_mvp_count(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)  \n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()  \n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # Find the <ul> element with id \"bling\"\n",
    "        bling_ul = soup.find('ul', {'id': 'bling'})\n",
    "        \n",
    "        if bling_ul:\n",
    "            mvp_count = None\n",
    "            for li in bling_ul.find_all('li'):\n",
    "                a_tag = li.find('a')\n",
    "                if a_tag and \"MVP\" in a_tag.text:\n",
    "                    if \"MVP\" in a_tag.text and \"Finals\" not in a_tag.text:\n",
    "                        mvp_count = re.search(r'\\d+x', a_tag.text)\n",
    "                        if mvp_count:\n",
    "                            return mvp_count.group().replace('x', '')\n",
    "            \n",
    "            if mvp_count is None:\n",
    "                return \"MVP count not found\"\n",
    "        else:\n",
    "            return \"Bling section not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# print(scrape_mvp_count(player_links[0]))"
   ],
   "id": "b1c646ab28945572",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape Finals MVP",
   "id": "ce62296297dec1ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:42:24.658615Z",
     "start_time": "2024-11-23T11:42:17.419148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_fmvp_count(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)  \n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()  \n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # Find the <ul> element with id \"bling\"\n",
    "        bling_ul = soup.find('ul', {'id': 'bling'})\n",
    "\n",
    "        if bling_ul:\n",
    "            fmvp_count = None\n",
    "            for li in bling_ul.find_all('li'):\n",
    "                a_tag = li.find('a')\n",
    "                if a_tag and \"Finals MVP\" in a_tag.text:\n",
    "                    fmvp_count = re.search(r'\\d+x', a_tag.text)\n",
    "                    if fmvp_count:\n",
    "                        return fmvp_count.group().replace('x', '')\n",
    "            \n",
    "            if fmvp_count is None:\n",
    "                return \"Finals MVP count not found\"\n",
    "        else:\n",
    "            return \"Bling section not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Call the function with the player link\n",
    "# print(scrape_fmvp_count(player_links[0]))"
   ],
   "id": "f9ad892797c98c53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape All NBA Team",
   "id": "7fec47cf528dc177"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:53:16.150593Z",
     "start_time": "2024-11-23T11:53:08.833509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_anbat_count(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # Find the <ul> element with id \"bling\"\n",
    "        bling_ul = soup.find('ul', {'id': 'bling'})\n",
    "\n",
    "        if bling_ul:\n",
    "            anbat_count = None\n",
    "            for li in bling_ul.find_all('li'):\n",
    "                a_tag = li.find('a')\n",
    "                if a_tag and \"All-NBA\" in a_tag.text:\n",
    "                    anbat_count = re.search(r'\\d+x', a_tag.text)\n",
    "                    if anbat_count:\n",
    "                        return anbat_count.group().replace('x', '')\n",
    "\n",
    "            if anbat_count is None:\n",
    "                return \"All-NBA Teams count not found\"\n",
    "        else:\n",
    "            return \"Bling section not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Call the function with the player link\n",
    "# print(scrape_anbat_count(player_links[0]))"
   ],
   "id": "885fd758580d97ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape NBA Championships Count",
   "id": "e0d6d5e7ccb5b580"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T12:02:33.868506Z",
     "start_time": "2024-11-23T12:02:26.395715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_nba_champ_count(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # Find the <ul> element with id \"bling\"\n",
    "        bling_ul = soup.find('ul', {'id': 'bling'})\n",
    "\n",
    "        if bling_ul:\n",
    "            nba_champ_count = None\n",
    "            for li in bling_ul.find_all('li'):\n",
    "                a_tag = li.find('a')\n",
    "                if a_tag and \"NBA Champ\" in a_tag.text:\n",
    "                    nba_champ_count = re.search(r'\\d+x', a_tag.text)\n",
    "                    if nba_champ_count:\n",
    "                        return nba_champ_count.group().replace('x', '')\n",
    "\n",
    "            if nba_champ_count is None:\n",
    "                return \"NBA Championships count not found\"\n",
    "        else:\n",
    "            return \"Bling section not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "    \n",
    "# Call the function with the player link\n",
    "print(scrape_nba_champ_count(player_links[0]))"
   ],
   "id": "9dd55a39a99ce0b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All Defensive Teams Count",
   "id": "c92fbd5873bd5390"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T12:04:41.889752Z",
     "start_time": "2024-11-23T12:04:34.527420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_all_def_team_count(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)\n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "                # Find the <ul> element with id \"bling\"\n",
    "        bling_ul = soup.find('ul', {'id': 'bling'})\n",
    "\n",
    "        if bling_ul:\n",
    "            all_def_team_count = None\n",
    "            for li in bling_ul.find_all('li'):\n",
    "                a_tag = li.find('a')\n",
    "                if a_tag and \"All-Defensive\" in a_tag.text:\n",
    "                    all_def_team_count = re.search(r'\\d+x', a_tag.text)\n",
    "                    if all_def_team_count:\n",
    "                        return all_def_team_count.group().replace('x', '')\n",
    "\n",
    "            if all_def_team_count is None:\n",
    "                return \"NBA Championships count not found\"\n",
    "        else:\n",
    "            return \"Bling section not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "        \n",
    "print(scrape_all_def_team_count(player_links[0]))"
   ],
   "id": "11e0e22c3c181cb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape PER Rating (Player Efficiency Rating)",
   "id": "4df3064498a47e35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T12:11:15.818769Z",
     "start_time": "2024-11-23T12:11:08.530159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_per(full_url):\n",
    "    url = full_url\n",
    "    try:\n",
    "        time.sleep(7)  \n",
    "        r = requests.get(url, headers=headers)\n",
    "        r.raise_for_status()  \n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        p1_div = soup.find(\"div\", {\"class\": \"p3\"})\n",
    "        if p1_div:\n",
    "            ppg_value_element = p1_div.find_all(\"p\")[1] \n",
    "            ppg_value = ppg_value_element.get_text()\n",
    "            return ppg_value.strip()\n",
    "        else:\n",
    "            return \"PPG information not found\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "print(scrape_per(player_links[0]))"
   ],
   "id": "1f0e36cc58ef864d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.6\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scrape Winshares/48",
   "id": "e0688a1e85940761"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T12:23:45.789117Z",
     "start_time": "2024-11-23T12:23:45.786300Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36a5e9f7d46f245f",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1c20d51d96b9525f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:24:06.915352Z",
     "start_time": "2024-11-23T11:13:55.907524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_ppg_list(player_link):\n",
    "    ppg_list = []\n",
    "    for player in player_link:\n",
    "        ppg_list.append(scrape_ppg(player))\n",
    "    return ppg_list\n",
    "ppg_values = scrape_ppg_list(player_links)\n",
    "print(ppg_values)"
   ],
   "id": "b9e4d19ccb0a9cbf",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[72], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m         ppg_list\u001B[38;5;241m.\u001B[39mappend(scrape_ppg(player))\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ppg_list\n\u001B[0;32m----> 6\u001B[0m ppg_values \u001B[38;5;241m=\u001B[39m scrape_ppg_list(player_links)\n",
      "Cell \u001B[0;32mIn[72], line 4\u001B[0m, in \u001B[0;36mscrape_ppg_list\u001B[0;34m(player_link)\u001B[0m\n\u001B[1;32m      2\u001B[0m ppg_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m player \u001B[38;5;129;01min\u001B[39;00m player_link:\n\u001B[0;32m----> 4\u001B[0m     ppg_list\u001B[38;5;241m.\u001B[39mappend(scrape_ppg(player))\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ppg_list\n",
      "Cell \u001B[0;32mIn[68], line 6\u001B[0m, in \u001B[0;36mscrape_ppg\u001B[0;34m(full_url)\u001B[0m\n\u001B[1;32m      3\u001B[0m headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMozilla/5.0\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m----> 6\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m7\u001B[39m)  \n\u001B[1;32m      7\u001B[0m     r \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url, headers\u001B[38;5;241m=\u001B[39mheaders)\n\u001B[1;32m      8\u001B[0m     r\u001B[38;5;241m.\u001B[39mraise_for_status()  \u001B[38;5;66;03m# Raise an exception for bad HTTP status codes\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_trb_list(player_link):\n",
    "    trb_list = []\n",
    "    for player in player_link:\n",
    "        trb_list.append(scrape_trb(player))\n",
    "    return trb_list\n",
    "trb_values = scrape_trb_list(player_links)\n",
    "print(trb_values)"
   ],
   "id": "ce21c34eb64f7709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_ast_list(player_link):\n",
    "    ast_list = []\n",
    "    for player in player_link:\n",
    "        ast_list.append(scrape_trb(player))\n",
    "    return ast_list\n",
    "ast_values = scrape_ast_list(player_links)\n",
    "print(ast_values)"
   ],
   "id": "f57385ae11e6dd56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_mvp_list(player_link):\n",
    "    mvp_list = []\n",
    "    for player in player_link:\n",
    "        mvp_list.append(scrape_mvp_count(player))\n",
    "    return mvp_list\n",
    "mvp_values = scrape_mvp_list(player_links)\n",
    "print(mvp_values)\n",
    "        "
   ],
   "id": "ddb88de38ace05ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scrape_anbat(player_link):\n",
    "    anbat_list = []\n",
    "    for player in player_links:\n",
    "        anbat_list.append(scrape_anbat_count(player))\n",
    "    return anbat_list\n",
    "anbat_values = scrape_anbat(player_links)\n",
    "print(anbat_values)\n",
    "        "
   ],
   "id": "1cca3e6143ae66c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "def ",
   "id": "754869f71afa1105"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T11:24:06.916187Z",
     "start_time": "2024-11-23T11:24:06.916128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = url_extensions_df['Player Name'] \n",
    "# df = ['PPG'] = ppg_values\n",
    "ppg_series = pd.DataFrame(ppg_values, columns=['PPG'])\n",
    "# df = url_extensions_df[['PPG']] = df_1\n",
    "df = pd.concat([df, ppg_series], axis=1)\n",
    "df"
   ],
   "id": "cf4147cb973f3003",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
